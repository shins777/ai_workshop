{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2896f7",
   "metadata": {
    "id": "ff2896f7"
   },
   "source": [
    "## Create Vector Search Dataset\n",
    "\n",
    "* Reference : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5329d6",
   "metadata": {
    "id": "ae5329d6"
   },
   "source": [
    "### Install and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11966b",
   "metadata": {
    "executionInfo": {
     "elapsed": 16317,
     "status": "ok",
     "timestamp": 1753419971641,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "aa11966b"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-genai \\\n",
    "                                numpy \\\n",
    "                                scipy \\\n",
    "                                pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwrAYYHFUQ6w",
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1753420147334,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "kwrAYYHFUQ6w"
   },
   "outputs": [],
   "source": [
    "#Set environment variables\n",
    "PROJECT_ID = \"ai-hangsik\" \n",
    "REGION = \"us-central1\"\n",
    "USE_VERTEX_AI = True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5492f7d",
   "metadata": {
    "id": "d5492f7d"
   },
   "outputs": [],
   "source": [
    "!gcloud auth application-default login\n",
    "!gcloud auth application-default set-quota-project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931ef0",
   "metadata": {
    "id": "16931ef0"
   },
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google import genai\n",
    "\n",
    "import embedding as embed_utils\n",
    "\n",
    "# Login to Vertex AI\n",
    "client = genai.Client(\n",
    "    vertexai=USE_VERTEX_AI,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38095478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read CSV file (assuming you have a CSV with a 'text' column)\n",
    "df = pd.read_csv('../embeddings/data/.audio_truth.csv',skipinitialspace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate embeddings for all texts\n",
    "# MODEL = \"text-multilingual-embedding-002\"\n",
    "MODEL = \"gemini-embedding-001\"\n",
    "\n",
    "df['feature_vector'] = df['text'].apply(lambda x: embed_utils.gemini_embedding_func(\n",
    "    client=client,\n",
    "    model=MODEL,\n",
    "    task_type=\"SEMANTIC_SIMILARITY\",\n",
    "    output_dimensionality=3072,\n",
    "    contents=x\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75801536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find similar texts for a query\n",
    "MODEL = \"gemini-embedding-001\"\n",
    "QUERY = \"오징어 있어?\"\n",
    "\n",
    "similar_texts = embed_utils.find_similar_texts(client, MODEL, QUERY, df)\n",
    "\n",
    "search_results = []\n",
    "# 4. Print results\n",
    "for result in similar_texts:\n",
    "    \n",
    "    search_results.append({\n",
    "        \"text\": result['text'],\n",
    "        \"similarity\": f\"{result['similarity']:.4f}\"\n",
    "    })\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4226fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "    당신은 사용자의 질문을 이해해서 정확한 질문의 의도를 바탕으로 사용자의 질문을 재작성해주는 AI 어시스턴트입니다.\n",
    "    사용자의 질문 : {QUERY} 과 검색된 유사한 질문들을 참고하여 최대한 사용자의 질문을 반영한 명확한 질문으로 재작성해 주세요.\n",
    "    유사한 질문들 : {search_results}    \n",
    "\n",
    "    답변은 아래와 같이 사용자의 질문을 최소화해서 변경 후 재작성 해주세요.\n",
    "    답변예제 : \"최신 개봉 영화 예고편 모음 틀어줘\" \n",
    "\"\"\"\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "latency = (end_time - start_time)\n",
    "print(f\"{MODEL} Latency (ns): {latency*1e-6:.2f} ms \\n\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434780bf",
   "metadata": {},
   "source": [
    "### Generate Dataset for Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read product-embs.json and put them to a list\n",
    "\n",
    "datapoints = []\n",
    "for index, item in df.iterrows():\n",
    "    id = str(item[\"datapoint_id\"])\n",
    "    metadata = item[\"text\"]\n",
    "    embedding = item[\"feature_vector\"]\n",
    "\n",
    "    datapoints.append(\n",
    "        {\n",
    "            \"datapoint_id\": str(id), \n",
    "            \"feature_vector\": embedding,\n",
    "            \"embedding_metadata\": \n",
    "                {\"text\": metadata},\n",
    "        }     \n",
    "    )\n",
    "\n",
    "datapoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a JSON string and write it to a file\n",
    "with open(\"vector_search_dataset.json\", \"w\", encoding='utf-8') as jsonl_file:\n",
    "    \n",
    "    for item in datapoints:\n",
    "        json_line = json.dumps(item, ensure_ascii=False)\n",
    "        print(json_line)\n",
    "        jsonl_file.write(json_line +'\\n')\n",
    "\n",
    "    # json.dump(datapoints, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5xH-7ZYBzFgA",
   "metadata": {
    "id": "5xH-7ZYBzFgA"
   },
   "source": [
    "## End of Document"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11R51JG9-2NCZhHRTqNzJPXqfFyV95uoI",
     "timestamp": 1753335275054
    },
    {
     "file_id": "10gZJu0E2iUQmlLPw26rXPjCCR4uFDwZ6",
     "timestamp": 1753325541712
    },
    {
     "file_id": "1aEpqQqoFTSDfbaZIxp_vmMKKVh0SupO5",
     "timestamp": 1753315305740
    },
    {
     "file_id": "1GoMGdpjOWcSfnDeO0E7Alge4UD1ThQu6",
     "timestamp": 1753312386672
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
