{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2896f7",
   "metadata": {
    "id": "ff2896f7"
   },
   "source": [
    "## Google Multimodal Embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5329d6",
   "metadata": {
    "id": "ae5329d6"
   },
   "source": [
    "### Install and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb959f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11966b",
   "metadata": {
    "executionInfo": {
     "elapsed": 16317,
     "status": "ok",
     "timestamp": 1753419971641,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "aa11966b"
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet google-genai \\\n",
    "#                                 numpy \\\n",
    "#                                 scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwrAYYHFUQ6w",
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1753420147334,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "kwrAYYHFUQ6w"
   },
   "outputs": [],
   "source": [
    "#Set environment variables\n",
    "PROJECT_ID = \"ai-hangsik\" \n",
    "REGION = \"us-central1\"\n",
    "# USE_VERTEX_AI = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5492f7d",
   "metadata": {
    "id": "d5492f7d"
   },
   "outputs": [],
   "source": [
    "!gcloud auth application-default login\n",
    "!gcloud auth application-default set-quota-project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931ef0",
   "metadata": {
    "id": "16931ef0"
   },
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.vision_models import Image, MultiModalEmbeddingModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l3U9eMllUdY2",
   "metadata": {
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1753420151532,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "l3U9eMllUdY2"
   },
   "outputs": [],
   "source": [
    "# Login to Vertex AI\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "\n",
    "# client = genai.Client(\n",
    "#     vertexai=USE_VERTEX_AI,\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z51TSX7cDR8R",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1753420153254,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Z51TSX7cDR8R"
   },
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two embedding arrays\n",
    "def cosine_similarity(embed_1, embed_2):\n",
    "  import numpy as np\n",
    "  from scipy.spatial.distance import cosine\n",
    "\n",
    "  embedding_1 = np.array(embed_1)\n",
    "  embedding_2 = np.array(embed_2)\n",
    "\n",
    "  cosine_similarity = 1 - cosine(embedding_1, embedding_2)\n",
    "  print(f\"Cosine similarity : {cosine_similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXAyq_qgArOK",
   "metadata": {
    "id": "cXAyq_qgArOK"
   },
   "source": [
    "### Google Embedding models\n",
    "* https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_pQpd3ho9W9Y",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753420154798,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "_pQpd3ho9W9Y"
   },
   "outputs": [],
   "source": [
    "# Generate embedding using given model, image path, and contextual text\n",
    "\n",
    "def generate_multimodal_embedding(model, image_path, contextual_text):\n",
    "  \n",
    "\tstart_time = time.perf_counter_ns()\n",
    "\n",
    "\tmodel = MultiModalEmbeddingModel.from_pretrained(model)\n",
    "\n",
    "\t# https://docs.cloud.google.com/python/docs/reference/vertexai/latest/vertexai.preview.vision_models.MultiModalEmbeddingModel#vertexai_preview_vision_models_MultiModalEmbeddingModel_get_embeddings\n",
    "\t\n",
    "\tembeddings = model.get_embeddings(\n",
    "\n",
    "\t\timage=Image.load_from_file(image_path),\n",
    "\t\tcontextual_text=contextual_text,\n",
    "\t\tdimension=1408, # dimension must be one of 128, 256, 512, 1408\n",
    "\n",
    "\t)\n",
    "\n",
    "\tend_time = time.perf_counter_ns()\n",
    "\n",
    "\tlatency = (end_time - start_time)\n",
    "\tprint(f\"Latency (ns): {latency*1e-6:.2f} ms\")\n",
    "\n",
    "\treturn embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c103ac",
   "metadata": {},
   "source": [
    "#### multimodalembedding@001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ig9GMpdd-Czd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1753420157373,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Ig9GMpdd-Czd",
    "outputId": "0f10b600-83dd-4b3a-feee-7fbcb2a9a12f"
   },
   "outputs": [],
   "source": [
    "MODEL = \"multimodalembedding@001\"\n",
    "IMAGE_PATH = \"gs://cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\"\n",
    "TEXT = \"Colosseum\"\n",
    "\n",
    "\n",
    "embeddings = generate_multimodal_embedding(model = MODEL,\n",
    "                                image_path = IMAGE_PATH,\n",
    "                                contextual_text = TEXT) \n",
    "\n",
    "print(f\"Generated embedding vector for image (length: {len(embeddings.image_embedding)}):\")\n",
    "print(f\"Generated embedding vector for text  (length: {len(embeddings.text_embedding)}):\")\n",
    "\n",
    "# cosine_similarity(embed_1, embed_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0810cc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel\n",
    "    \n",
    "def generate_text_embedding(model, contextual_text):\n",
    "\n",
    "    \n",
    "\tstart_time = time.perf_counter_ns() \n",
    "\n",
    "\tmodel = TextEmbeddingModel.from_pretrained(model)\n",
    "\n",
    "\t# https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#parameter-list\n",
    "\n",
    "\tinstances = [\n",
    "\t\t{\n",
    "\t\t\t\"task_type\": \"RETRIEVAL_QUERY\",\n",
    "\t\t\t\"content\": contextual_text,\n",
    "\t\t\t#\"title\": \"content's title if needed\"\n",
    "\t\t}\n",
    "\t]\n",
    "\n",
    "\tparameters = {\n",
    "\t\t\"autoTruncate\" : True,\n",
    "\t\t\"outputDimensionality\": 1024,  # dimension must be one of 128, 256, 512, 1024\n",
    "\n",
    "\t}\n",
    "\n",
    "\tembeddings = model.get_embeddings(\n",
    "\n",
    "\t\tinstances=instances,\n",
    "\t\tparameters=parameters\n",
    "\t\t\n",
    "\n",
    "\t)\n",
    "\n",
    "\tend_time = time.perf_counter_ns()\n",
    "\n",
    "\tlatency = (end_time - start_time)\n",
    "\tprint(f\"Latency (ns): {latency*1e-6:.2f} ms\")\n",
    "\n",
    "\treturn embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"text-multilingual-embedding-002\"\n",
    "TEXT = \"고양이가 자전거를 타고 간다\"\n",
    "\n",
    "\n",
    "embeddings = generate_text_embedding(model = MODEL,\n",
    "                                contextual_text = TEXT) \n",
    "\n",
    "print(f\"Generated embedding vector for text (length: {len(embeddings.text_embedding)}):\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5xH-7ZYBzFgA",
   "metadata": {
    "id": "5xH-7ZYBzFgA"
   },
   "source": [
    "## End of Document"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11R51JG9-2NCZhHRTqNzJPXqfFyV95uoI",
     "timestamp": 1753335275054
    },
    {
     "file_id": "10gZJu0E2iUQmlLPw26rXPjCCR4uFDwZ6",
     "timestamp": 1753325541712
    },
    {
     "file_id": "1aEpqQqoFTSDfbaZIxp_vmMKKVh0SupO5",
     "timestamp": 1753315305740
    },
    {
     "file_id": "1GoMGdpjOWcSfnDeO0E7Alge4UD1ThQu6",
     "timestamp": 1753312386672
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
