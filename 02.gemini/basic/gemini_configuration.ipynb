{"cells":[{"cell_type":"markdown","id":"ff2896f7","metadata":{"id":"ff2896f7"},"source":["## Gemini 실행 설정"]},{"cell_type":"markdown","id":"ae5329d6","metadata":{"id":"ae5329d6"},"source":["### 1. 라이브러리 설치"]},{"cell_type":"code","execution_count":1,"id":"aa11966b","metadata":{"id":"aa11966b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753323635691,"user_tz":-540,"elapsed":8511,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"75d9e74b-aae1-4fe9-eac7-4fd58907398a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.5/218.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install --upgrade --quiet google-genai"]},{"cell_type":"markdown","id":"c5481f87","metadata":{"id":"c5481f87"},"source":["### 2. GCP 환경설정 및 로그인"]},{"cell_type":"code","source":["import os\n","\n","PROJECT_ID = \"ai-hangsik\" #@param {type:\"string\"}\n","REGION = \"us-central1\" #@param {type:\"string\"}\n","USE_VERTEX_AI = True #@param {type:\"boolean\"}\n","MODEL = \"gemini-2.5-flash\" #@param {type:\"string\"}"],"metadata":{"id":"bR9U7jSulgRl","executionInfo":{"status":"ok","timestamp":1753323869524,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"id":"bR9U7jSulgRl","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d5492f7d","metadata":{"id":"d5492f7d"},"outputs":[],"source":["!gcloud auth application-default login\n","!gcloud auth application-default set-quota-project {PROJECT_ID}"]},{"cell_type":"markdown","id":"16931ef0","metadata":{"id":"16931ef0"},"source":["### 3. Vertex AI Client 실행"]},{"cell_type":"code","source":["import base64\n","from IPython.display import Image, display, Markdown\n","\n","from google import genai\n","from google.genai import types\n","from google.genai.types import HttpOptions\n","\n","client = genai.Client(\n","    vertexai=USE_VERTEX_AI,\n","    project=PROJECT_ID,\n","    location=REGION,)"],"metadata":{"id":"62dGhq6dOqvV","executionInfo":{"status":"ok","timestamp":1753323674943,"user_tz":-540,"elapsed":1667,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"id":"62dGhq6dOqvV","execution_count":4,"outputs":[]},{"cell_type":"code","source":["contents = [\n","  types.Content(\n","    role=\"user\",\n","    parts=[\n","      types.Part.from_text(text=\"\"\"트랜스포머 아키텍처에서 인코더란? \"\"\")\n","    ]\n","  )\n","]\n","\n","# https://googleapis.github.io/python-genai/genai.html#genai.types.GenerateContentConfig\n","generate_content_config = types.GenerateContentConfig(\n","  system_instruction = \"당신은 AI 기술에 대한 전문가입니다. 답변시 전문적인 용어를 활용해서 답해주세요.\",\n","  temperature = 1,\n","  top_p = 0.95,\n","  max_output_tokens = 65535,\n","\n","  safety_settings = [types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\",threshold=\"OFF\"),\n","                      types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",threshold=\"OFF\"),\n","                      types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",threshold=\"OFF\"),\n","                      types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\",threshold=\"OFF\")\n","                      ],\n","  thinking_config=types.ThinkingConfig(\n","    thinking_budget=0,\n","  ),\n",")\n"],"metadata":{"id":"sns_STC7PDPE","executionInfo":{"status":"ok","timestamp":1753324776553,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"id":"sns_STC7PDPE","execution_count":14,"outputs":[]},{"cell_type":"code","source":["resonse = client.models.generate_content_stream(\n","      model = MODEL,\n","\n","      contents = contents,\n","      config = generate_content_config,\n","  )\n","\n","for chunk in resonse:\n","  print(chunk.text, end=\"\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRMzYxmKPa0M","executionInfo":{"status":"ok","timestamp":1753324794495,"user_tz":-540,"elapsed":15453,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5c595155-2249-408a-8d4d-c9112bb41489"},"id":"DRMzYxmKPa0M","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["## 트랜스포머 아키텍처에서 인코더의 역할: 심층적인 분석\n","\n","트랜스포머(Transformer) 아키텍처에서 인코더(Encoder)는 입력 시퀀스(Input Sequence)의 의미론적(Semantic) 및 구문론적(Syntactic) 정보를 추출하여 고차원(High-dimensional)의 잠재 공간(Latent Space) 표현으로 변환하는 핵심 구성 요소입니다. 이는 전통적인 순환 신경망(Recurrent Neural Network, RNN) 계열 모델들의 단점인 장거리 의존성(Long-range Dependency) 문제를 효과적으로 해결하며 병렬 처리(Parallel Processing)를 가능하게 합니다.\n","\n","### 1. 인코더의 기본 구조 및 동작 원리\n","\n","트랜스포머의 인코더는 동일한 구조의 여러 스택된(Stacked) 레이어(Layer)로 구성됩니다. 각 인코더 레이어는 크게 두 가지 하위 레이어(Sub-layer)를 포함합니다.\n","\n","#### 1.1. 멀티-헤드 어텐션 (Multi-Head Attention)\n","\n","*   **동작 원리:** 멀티-헤드 어텐션은 입력 시퀀스 내의 각 토큰(Token)이 다른 모든 토큰과의 관계를 동시에 학습할 수 있도록 합니다. 이는 쿼리(Query, $Q$), 키(Key, $K$), 값(Value, $V$)이라는 세 가지 행렬을 사용합니다.\n","    *   $Q$: 현재 처리 중인 토큰의 정보를 담고 있습니다.\n","    *   $K$: 시퀀스 내의 모든 토큰에 대한 정보를 담고 있습니다.\n","    *   $V$: 시퀀스 내의 모든 토큰의 실제 내용(정보)을 담고 있습니다.\n","*   **수식:** 스케일드 닷-프로덕트 어텐션(Scaled Dot-Product Attention)은 다음과 같이 정의됩니다.\n","    $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V $$\n","    여기서 $d_k$는 키 벡터의 차원입니다. 이를 통해 쿼리와 키의 유사도를 계산하고, 소프트맥스(softmax) 함수를 적용하여 어텐션 가중치(Attention Weight)를 생성합니다. 이 가중치를 값에 곱하여 가중 평균(Weighted Average)을 계산함으로써, 각 토큰이 시퀀스 내의 다른 토큰들 중 어떤 토큰에 더 집중해야 하는지를 학습합니다.\n","*   **멀티-헤드:** 단일 어텐션 메커니즘 대신 여러 개의 \"헤드(Head)\"를 병렬적으로 사용하여 각 헤드가 서로 다른 관점(Representation Subspace)에서 입력 시퀀스를 분석합니다. 예를 들어, 한 헤드는 구문론적 관계(예: 주어-동사), 다른 헤드는 의미론적 관계(예: 동의어)를 학습할 수 있습니다. 각 헤드의 출력은 연결(Concatenate)된 후 선형 변환(Linear Transformation)을 거쳐 최종 멀티-헤드 어텐션 출력을 생성합니다.\n","\n","#### 1.2. 피드-포워드 네트워크 (Feed-Forward Network, FFN)\n","\n","*   **동작 원리:** 멀티-헤드 어텐션 레이어의 출력을 입력으로 받아 각 위치(Position)에 독립적으로 적용되는 두 개의 선형 변환과 비선형 활성화 함수(Non-linear Activation Function, 일반적으로 ReLU)로 구성됩니다. 이는 입력 표현을 더 고차원의 잠재 공간으로 매핑하고, 복잡한 비선형 패턴을 학습할 수 있도록 합니다.\n","    $$ \\text{FFN}(x) = \\text{max}(0, xW_1 + b_1)W_2 + b_2 $$\n","    여기서 $W_1, W_2$는 가중치 행렬이고, $b_1, b_2$는 편향 벡터입니다.\n","\n","#### 1.3. 잔차 연결 및 레이어 정규화 (Residual Connections & Layer Normalization)\n","\n","*   **잔차 연결 (Residual Connections):** 각 하위 레이어의 입력과 출력을 더하는 방식으로 구성됩니다($x + \\text{Sublayer}(x)$). 이는 깊은 네트워크에서의 기울기 소실(Vanishing Gradient) 문제를 완화하고, 학습을 안정화시키는 데 기여합니다.\n","*   **레이어 정규화 (Layer Normalization):** 각 하위 레이어의 출력에 적용됩니다. 배치 정규화(Batch Normalization)와 달리 배치(Batch) 차원이 아닌 특징(Feature) 차원에 대해 평균과 분산을 계산하여 정규화합니다. 이는 배치 크기에 독립적이며, 순환 신경망과 같이 가변적인 시퀀스 길이에 적합합니다.\n","\n","### 2. 인코더의 주요 기능 및 기여\n","\n","트랜스포머 아키텍처에서 인코더는 다음과 같은 중요한 기능을 수행합니다.\n","\n","*   **입력 시퀀스의 고차원 표현 학습:** 단어 임베딩(Word Embedding)과 위치 인코딩(Positional Encoding)을 통해 초기 입력 시퀀스를 벡터 공간으로 매핑하고, 어텐션 메커니즘을 통해 문맥적 의미를 반영한 풍부한 표현(Contextualized Representation)을 생성합니다.\n","*   **장거리 의존성 해결:** RNN 계열 모델의 순차적 처리 방식과 달리, 어텐션 메커니즘은 시퀀스 내의 모든 토큰 간의 직접적인 관계를 계산할 수 있으므로, 거리가 멀리 떨어진 토큰 간의 의존성도 효과적으로 포착합니다. 이는 \"나는 집에 **가고** 싶다. 그러나 **갈** 수 없다.\"와 같은 문장에서 '가고'와 '갈' 사이의 관계를 명확히 이해하는 데 중요합니다.\n","*   **병렬 처리 가능:** 순차적인 계산을 요구하는 RNN과 달리, 어텐션 메커니즘은 각 토큰에 대해 동시에 계산될 수 있습니다. 이는 GPU와 같은 병렬 처리 장치를 활용하여 학습 속도를 크게 향상시킵니다.\n","*   **문맥 정보 인코딩:** 어텐션 메커니즘을 통해 각 단어가 문장 내의 다른 단어들과 어떤 관계를 가지는지 학습함으로써, 동음이의어(Homonym)나 다의어(Polysemy)와 같은 단어의 모호성을 문맥에 따라 해석할 수 있습니다. 예를 들어, \"Bank\"라는 단어가 \"강둑\"을 의미하는지 \"금융 기관\"을 의미하는지 문맥을 통해 파악합니다.\n","\n","### 3. 인코더의 응용 및 확장\n","\n","트랜스포머의 인코더 부분은 자연어 처리(Natural Language Processing, NLP)의 다양한 분야에서 독립적으로 활용되거나, 디코더(Decoder)와 결합되어 사용됩니다.\n","\n","*   **인코더-온리(Encoder-only) 모델:** BERT(Bidirectional Encoder Representations from Transformers)와 같은 모델들은 트랜스포머 인코더만을 사용하여 텍스트의 양방향 문맥 표현을 학습합니다. 이들은 주로 텍스트 분류(Text Classification), 개체명 인식(Named Entity Recognition, NER), 질의 응답(Question Answering)과 같은 이해 기반(Understanding-based) 태스크에 활용됩니다.\n","*   **인코더-디코더(Encoder-Decoder) 모델:** 기계 번역(Machine Translation), 요약(Summarization), 텍스트 생성(Text Generation)과 같은 시퀀스-투-시퀀스(Sequence-to-Sequence, Seq2Seq) 태스크에 사용됩니다. 인코더는 소스 시퀀스(Source Sequence)를 인코딩하고, 디코더는 인코딩된 정보를 기반으로 타겟 시퀀스(Target Sequence)를 생성합니다.\n","*   **멀티모달 트랜스포머:** 텍스트뿐만 아니라 이미지, 오디오와 같은 다양한 모달리티(Modality)의 데이터를 인코딩하는 데에도 트랜스포머 인코더 구조가 확장되어 사용됩니다 (예: ViT(Vision Transformer) for Image Classification).\n","\n","### 결론\n","\n","트랜스포머 아키텍처의 인코더는 어텐션 메커니즘을 통해 입력 시퀀스의 복잡한 관계와 문맥적 정보를 효율적으로 인코딩하는 강력한 구성 요소입니다. 이는 NLP 분야에 혁명적인 발전을 가져왔으며, 기존 모델들의 한계를 극복하고 다양한 인공지능 응용 분야에서 핵심적인 역할을 수행하고 있습니다. 인코더의 심층적인 이해는 트랜스포머 기반 모델들의 동작 원리를 파악하고 새로운 아키텍처를 설계하는 데 필수적입니다."]}]},{"cell_type":"markdown","source":["### GenerateContentConfig\n","https://googleapis.github.io/python-genai/genai.html#genai.types.GenerateContentConfig\n","\n","Configurable Fields:  \n","* audio_timestamp (bool | None)\n","* automatic_function_calling (genai.types.AutomaticFunctionCallingConfig | None)\n","* cached_content (str | None)\n","* candidate_count (int | None)\n","* frequency_penalty (float | None)\n","* http_options (genai.types.HttpOptions | None)\n","* labels (dict[str, str] | None)\n","* logprobs (int | None)\n","* max_output_tokens (int | None)\n","* media_resolution (genai.types.MediaResolution | None)\n","* model_selection_config (genai.types.ModelSelectionConfig | None)\n","* presence_penalty (float | None)\n","* response_json_schema (Any | None)\n","* response_logprobs (bool | None)\n","* response_mime_type (str | None)\n","* response_modalities (list[str] | None)\n","* response_schema (dict[Any, Any] | type | genai.types.Schema | types GenericAlias | types.UnionType | _UnionGenericAlias | None)\n","* routing_config (genai.types.GenerationConfigRoutingConfig | None)\n","* safety_settings (list[genai.types.SafetySetting] | None)\n","* seed (int | None)\n","* speech_config (genai.types.SpeechConfig | str | None)\n","* stop_sequences (list[str] | None)\n","* system_instruction (genai.types.Content | list[genai.types.File | genai.types.Part | PIL.Image.Image | str] | genai.types.File | genai.types.Part | PIL.Image.Image | str | None)\n","* temperature (float | None)\n","* thinking_config (genai.types.ThinkingConfig | None)\n","* tool_config (genai.types.ToolConfig | None)\n","* tools (list[genai.types.Tool | Callable[[...], Any] | mcp.types.Tool | mcp.client.session.ClientSession] | None)\n","* top_k (float | None)\n","* top_p (float | None)"],"metadata":{"id":"Hbku0UqYTXlf"},"id":"Hbku0UqYTXlf"},{"cell_type":"markdown","source":["## End of Document"],"metadata":{"id":"5xH-7ZYBzFgA"},"id":"5xH-7ZYBzFgA"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.0"},"colab":{"provenance":[{"file_id":"1aEpqQqoFTSDfbaZIxp_vmMKKVh0SupO5","timestamp":1753315305740},{"file_id":"1GoMGdpjOWcSfnDeO0E7Alge4UD1ThQu6","timestamp":1753312386672}],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}