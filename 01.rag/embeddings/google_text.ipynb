{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2896f7",
   "metadata": {
    "id": "ff2896f7"
   },
   "source": [
    "## Google Text Embedding models\n",
    "\n",
    "* Reference : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5329d6",
   "metadata": {
    "id": "ae5329d6"
   },
   "source": [
    "### Install and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11966b",
   "metadata": {
    "executionInfo": {
     "elapsed": 16317,
     "status": "ok",
     "timestamp": 1753419971641,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "aa11966b"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-genai \\\n",
    "                                numpy \\\n",
    "                                scipy \\\n",
    "                                pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwrAYYHFUQ6w",
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1753420147334,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "kwrAYYHFUQ6w"
   },
   "outputs": [],
   "source": [
    "#Set environment variables\n",
    "PROJECT_ID = \"ai-hangsik\" \n",
    "REGION = \"us-central1\"\n",
    "USE_VERTEX_AI = True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5492f7d",
   "metadata": {
    "id": "d5492f7d"
   },
   "outputs": [],
   "source": [
    "!gcloud auth application-default login\n",
    "!gcloud auth application-default set-quota-project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931ef0",
   "metadata": {
    "id": "16931ef0"
   },
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import EmbedContentConfig\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l3U9eMllUdY2",
   "metadata": {
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1753420151532,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "l3U9eMllUdY2"
   },
   "outputs": [],
   "source": [
    "# Login to Vertex AI\n",
    "client = genai.Client(\n",
    "    vertexai=USE_VERTEX_AI,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z51TSX7cDR8R",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1753420153254,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Z51TSX7cDR8R"
   },
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two embedding arrays\n",
    "def cosine_similarity(embed_1, embed_2):\n",
    "  import numpy as np\n",
    "  from scipy.spatial.distance import cosine\n",
    "\n",
    "  embedding_1 = np.array(embed_1)\n",
    "  embedding_2 = np.array(embed_2)\n",
    "\n",
    "  cosine_similarity = 1 - cosine(embedding_1, embedding_2)\n",
    "  print(f\"Cosine similarity : {cosine_similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXAyq_qgArOK",
   "metadata": {
    "id": "cXAyq_qgArOK"
   },
   "source": [
    "### Google Text Embedding models\n",
    "* Manual web site : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#google-models\n",
    "* Related to task types: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/task-type-embedding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_pQpd3ho9W9Y",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753420154798,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "_pQpd3ho9W9Y"
   },
   "outputs": [],
   "source": [
    "# Generate embedding using text-multilingual\n",
    "def gemini_embedding_func(model:str, \n",
    "                          contents,\n",
    "                          task_type:str=\"SEMANTIC_SIMILARITY\",    \n",
    "                          output_dimensionality:int=768,\n",
    "                          ):\n",
    "  \n",
    "        start_time = time.perf_counter_ns()\n",
    "\n",
    "        # https://googleapis.github.io/python-genai/genai.html#genai.types.EmbedContentConfig\n",
    "        embed_config = EmbedContentConfig(\n",
    "                auto_truncate=True,\n",
    "                \n",
    "                # task types ref : https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#parameter-list\n",
    "                \n",
    "                task_type=task_type,  \n",
    "                \n",
    "                mime_type=\"text/plain\",\n",
    "                \n",
    "                output_dimensionality=output_dimensionality,  \n",
    "                \n",
    "                # title=\"title of the text\" # when task type is RETRIEVAL_DOCUMENT\n",
    "        )\n",
    "\n",
    "        result = client.models.embed_content(\n",
    "                model=model,\n",
    "                contents=contents,\n",
    "                config=embed_config\n",
    "        )\n",
    "\n",
    "        end_time = time.perf_counter_ns()\n",
    "\n",
    "        latency = (end_time - start_time)\n",
    "        print(f\"Latency (ns): {latency*1e-6:.2f} ms\")\n",
    "\n",
    "        return result.embeddings[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c103ac",
   "metadata": {},
   "source": [
    "#### text-multilingual-embedding-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ig9GMpdd-Czd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1753420157373,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Ig9GMpdd-Czd",
    "outputId": "0f10b600-83dd-4b3a-feee-7fbcb2a9a12f"
   },
   "outputs": [],
   "source": [
    "MODEL = \"text-multilingual-embedding-002\"\n",
    "\n",
    "CONTENT_1 = \"고양이가 자전거를 타고 간다\"\n",
    "CONTENT_2 = \"호랑이가 차를 차고 가고 있고 고양이도 자전거를 타고 뒤따르고 있다\"\n",
    "\n",
    "embed_1 = gemini_embedding_func(model = MODEL, \n",
    "                                task_type=\"SEMANTIC_SIMILARITY\", \n",
    "                                output_dimensionality=768,  \n",
    "                                contents = CONTENT_1)\n",
    "\n",
    "embed_2 = gemini_embedding_func(model = MODEL, \n",
    "                                task_type=\"SEMANTIC_SIMILARITY\", \n",
    "                                output_dimensionality=768,  \n",
    "                                contents = CONTENT_2)\n",
    "\n",
    "cosine_similarity(embed_1, embed_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c7b99",
   "metadata": {},
   "source": [
    "#### gemini embedding\n",
    "\n",
    "* https://arxiv.org/pdf/2503.07891\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-embedding-001\"\n",
    "\n",
    "CONTENT_1 = \"하이라키 마지막 회 틀어줘\"\n",
    "CONTENT_2 = \"하이라이트 마지막에 틀어 줘\"\n",
    "\n",
    "embed_1 = gemini_embedding_func(model = MODEL, \n",
    "                                task_type=\"SEMANTIC_SIMILARITY\", \n",
    "                                output_dimensionality=3072,  \n",
    "                                contents = CONTENT_1)\n",
    "\n",
    "embed_2 = gemini_embedding_func(model = MODEL, \n",
    "                                task_type=\"SEMANTIC_SIMILARITY\", \n",
    "                                output_dimensionality=3072,  \n",
    "                                contents = CONTENT_2)\n",
    "\n",
    "cosine_similarity(embed_1, embed_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e997d",
   "metadata": {},
   "source": [
    "### Find similar texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def find_similar_texts(query_text, df, embedding_column='embedding', text_column='text', top_k=5):\n",
    "    # Generate embedding for query text\n",
    "    query_embedding = gemini_embedding_func(\n",
    "        model=MODEL,\n",
    "        task_type=\"SEMANTIC_SIMILARITY\",\n",
    "        output_dimensionality=3072,\n",
    "        contents=query_text\n",
    "    )\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for idx, row in df.iterrows():\n",
    "        similarity = 1 - cosine(query_embedding, row[embedding_column])\n",
    "        similarities.append({'text': row[text_column], 'similarity': similarity})\n",
    "    \n",
    "    # Sort by similarity and get top k results\n",
    "    results = sorted(similarities, key=lambda x: x['similarity'], reverse=True)[:top_k]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38095478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# 1. Read CSV file (assuming you have a CSV with a 'text' column)\n",
    "df = pd.read_csv('data/.audio_truth.csv',skipinitialspace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate embeddings for all texts\n",
    "\n",
    "MODEL = \"gemini-embedding-001\"\n",
    "\n",
    "df['embedding'] = df['text'].apply(lambda x: gemini_embedding_func(\n",
    "    model=MODEL,\n",
    "    task_type=\"SEMANTIC_SIMILARITY\",\n",
    "    output_dimensionality=3072,\n",
    "    contents=x\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75801536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find similar texts for a query\n",
    "query = \"오징어 게임 있어?\"\n",
    "similar_texts = find_similar_texts(query, df)\n",
    "\n",
    "search_results = []\n",
    "# 4. Print results\n",
    "for result in similar_texts:\n",
    "    \n",
    "    search_results.append({\n",
    "        \"text\": result['text'],\n",
    "        \"similarity\": f\"{result['similarity']:.4f}\"\n",
    "    })\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4226fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "    당신은 사용자의 질문을 이해해서 정확한 질문의 의도를 바탕으로 사용자의 질문을 재작성해주는 AI 어시스턴트입니다.\n",
    "    사용자의 질문 : {query} 과 검색된 유사한 질문들을 참고하여 최대한 사용자의 질문을 반영한 명확한 질문으로 재작성해 주세요.\n",
    "    유사한 질문들 : {search_results}    \n",
    "\n",
    "    답변은 아래와 같이 사용자의 질문을 최소화해서 변경 후 재작성 해주세요.\n",
    "    답변예제 : \"최신 개봉 영화 예고편 모음 틀어줘\" \n",
    "\"\"\"\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "latency = (end_time - start_time)\n",
    "print(f\"{MODEL} Latency (ns): {latency*1e-6:.2f} ms \\n\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5xH-7ZYBzFgA",
   "metadata": {
    "id": "5xH-7ZYBzFgA"
   },
   "source": [
    "## End of Document"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11R51JG9-2NCZhHRTqNzJPXqfFyV95uoI",
     "timestamp": 1753335275054
    },
    {
     "file_id": "10gZJu0E2iUQmlLPw26rXPjCCR4uFDwZ6",
     "timestamp": 1753325541712
    },
    {
     "file_id": "1aEpqQqoFTSDfbaZIxp_vmMKKVh0SupO5",
     "timestamp": 1753315305740
    },
    {
     "file_id": "1GoMGdpjOWcSfnDeO0E7Alge4UD1ThQu6",
     "timestamp": 1753312386672
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
